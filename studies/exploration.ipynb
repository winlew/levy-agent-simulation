{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploration Study\n",
    "**Objective**: Test which blind exploration regime is optimal. Compare Lévy walk like motion to ballistic motion.\n",
    "\n",
    "Agents forage for randomly distributed food particles in a 2D environment.\n",
    "How much food does each strategy consume?\n",
    "\n",
    "Consider:\n",
    "- blind\n",
    "- independent\n",
    "- non evolving\n",
    "\n",
    "agents that are randomly placed in the environment.\n",
    "All agents behave the same. So placing $n$ agents in the environment is the same as randomly initializing one agent $n$ times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(os.path.join(os.getcwd(), \"../code\"))\n",
    "\n",
    "from environment import Environment\n",
    "from simulation import Params\n",
    "from data_io import initialize_epoch_data, save_simulation_context, save_epoch_data, update_epoch_data, update_meal_timelines\n",
    "from simulation import Simulation\n",
    "import numpy as np\n",
    "from agent import LévyAgent, BallisticAgent\n",
    "from visualization import animate_single_iteration\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_FOOD = 100\n",
    "SIZE = 100\n",
    "VELOCITY = 1\n",
    "EAT_RADIUS = 1\n",
    "NUM_ITERATIONS = 1\n",
    "POPULATION_SIZE = 20\n",
    "TOTAL_TIME = 499\n",
    "DELTA_T = 1\n",
    "\n",
    "RUNS = 2\n",
    "ADD_FOOD_MANUALLY = False\n",
    "WALLS = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = Params(\n",
    "    num_food = NUM_FOOD,\n",
    "    size = SIZE,\n",
    "    velocity = VELOCITY,\n",
    "    eat_radius = EAT_RADIUS,\n",
    "    iterations_per_epoch = NUM_ITERATIONS,\n",
    "    num_epochs = 1,\n",
    "    population_size = POPULATION_SIZE,\n",
    "    total_time = TOTAL_TIME,\n",
    "    delta_t = DELTA_T,\n",
    "    empty = False,\n",
    "    border_buffer = 2,\n",
    "    food_buffer = 2,\n",
    "    perception_radius = EAT_RADIUS\n",
    ")\n",
    "\n",
    "environment = Environment(params)\n",
    "\n",
    "if WALLS:\n",
    "    environment.add_wall(np.array([0, 0]), np.array([0, params.size]))\n",
    "    environment.add_wall(np.array([0, 0]), np.array([params.size, 0]))\n",
    "    environment.add_wall(np.array([params.size, 0]), np.array([params.size, params.size]))\n",
    "    environment.add_wall(np.array([0, params.size]), np.array([params.size, params.size]))\n",
    "\n",
    "if ADD_FOOD_MANUALLY:\n",
    "    environment.custom_food_positioning()\n",
    "    params.num_food = environment.num_food\n",
    "\n",
    "folder = 'exploration_study'\n",
    "save_simulation_context(folder, environment, params)\n",
    "\n",
    "consumptions_levy = []\n",
    "consumptions_ballistic = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lévy Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_lévy():\n",
    "    population = []\n",
    "    for _ in range(params.population_size):\n",
    "        agent = LévyAgent(params)\n",
    "        population.append(agent)\n",
    "\n",
    "    data = initialize_epoch_data(params)\n",
    "    sim = Simulation(params)\n",
    "\n",
    "    for _ in range(sim.iterations_per_epoch):\n",
    "        sim.recycle_agents(population, environment, step=0)\n",
    "        for step in tqdm(range(params.simulation_steps - 1)):\n",
    "            for agent in population:\n",
    "                agent.perceive(environment)\n",
    "                if agent.pending_steps == 0:\n",
    "                    agent.choose_action()\n",
    "                agent.pending_steps -= 1\n",
    "                new_position = agent.position + np.array([np.cos(agent.direction), np.sin(agent.direction)]) * agent.velocity * params.delta_t\n",
    "                agent.move(new_position, environment)\n",
    "            sim.store_positions(population, step + 1)\n",
    "        sim.store_consumed_meals(population)\n",
    "        update_meal_timelines(data, sim.iteration, population)\n",
    "        update_epoch_data(data, sim.iteration, sim.trajectory_log, sim.meals_per_iteration)\n",
    "        sim.iteration += 1\n",
    "\n",
    "    # save_epoch_data(folder + '/levy_data', data, None, params.num_epochs)\n",
    "    # animate_single_iteration(params.iterations_per_epoch - 1, environment, params, data, folder, 'levy_mu1', 0, elite_only = False)\n",
    "    consumptions_levy.append(data['meals'].values.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ballistic Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_ballistic():\n",
    "    population = []\n",
    "    for _ in range(params.population_size):\n",
    "        agent = BallisticAgent(params)\n",
    "        population.append(agent)\n",
    "\n",
    "    data = initialize_epoch_data(params)\n",
    "    sim = Simulation(params)\n",
    "\n",
    "    for _ in range(sim.iterations_per_epoch):\n",
    "        sim.recycle_agents(population, environment, step=0)\n",
    "        for step in tqdm(range(params.simulation_steps - 1)):\n",
    "            for agent in population:\n",
    "                agent.perceive(environment)\n",
    "                new_position = agent.position + np.array([np.cos(agent.direction), np.sin(agent.direction)]) * agent.velocity * params.delta_t\n",
    "                agent.move(new_position, environment)\n",
    "            sim.store_positions(population, step + 1)\n",
    "        sim.store_consumed_meals(population)\n",
    "        update_meal_timelines(data, sim.iteration, population)\n",
    "        update_epoch_data(data, sim.iteration, sim.trajectory_log, sim.meals_per_iteration)\n",
    "        sim.iteration += 1\n",
    "\n",
    "    # save_epoch_data(folder + '/ballistic_data', data, None, params.num_epochs)\n",
    "    # animate_single_iteration(params.iterations_per_epoch - 1, environment, params, data, folder, 'ballistic', 0, elite_only = False)\n",
    "    consumptions_ballistic.append(data['meals'].values.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 499/499 [00:01<00:00, 268.68it/s]\n",
      "100%|██████████| 499/499 [00:01<00:00, 272.68it/s]\n",
      "100%|██████████| 499/499 [00:01<00:00, 266.87it/s]\n",
      "100%|██████████| 499/499 [00:01<00:00, 272.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average number of food particles eaten by Lévy agents over all runs:       99.5\n",
      "average number of food particles eaten by ballistic agents over all runs:  185.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for _ in range(RUNS):\n",
    "    run_lévy()\n",
    "    run_ballistic()\n",
    "\n",
    "# calculate average consumtions\n",
    "consumptions_levy = np.array(consumptions_levy)\n",
    "consumptions_ballistic = np.array(consumptions_ballistic)\n",
    "print('average number of food particles eaten by Lévy agents over all runs:      ', consumptions_levy.mean())\n",
    "print('average number of food particles eaten by ballistic agents over all runs: ', consumptions_ballistic.mean())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "levy-agent-simulation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
